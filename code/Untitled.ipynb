{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab74c9a-8e55-4dde-8541-4705b66d7b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bert4torch.tokenizers import Tokenizer\n",
    "from bert4torch.models import build_transformer_model, BaseModel\n",
    "from bert4torch.snippets import sequence_padding, text_segmentate, ListDataset\n",
    "from bert4torch.snippets import seed_everything, Callback, get_pool_emb\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f23491-ea6a-4444-a962-49bb5dd0839a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711280cd-6fb5-4aa0-8cae-b63dc8c0604c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m[INFO]\u001b[0m Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# 固定seed\n",
    "seed_everything(42)\n",
    "maxlen = 30\n",
    "batch_size = 16\n",
    "pretrained_dir = './'\n",
    "config_path = pretrained_dir+'bert_config.json'\n",
    "checkpoint_path = pretrained_dir+'pytorch_model.bin'\n",
    "dict_path = pretrained_dir+'vocab.txt'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c991c-94cf-448b-9b6c-24a20ba94b02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd977d37-3bf0-4895-a69e-a68a3bf40da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "# 加载数据集\n",
    "class MyDataset(ListDataset):\n",
    "    @staticmethod\n",
    "    def load_data(filenames):\n",
    "        \"\"\"加载数据，并尽量划分为不超过maxlen的句子\n",
    "        \"\"\"\n",
    "        D = []\n",
    "        seps, strips = u'\\n。！？!?；;，, ', u'；;，, '\n",
    "        for filename in filenames:\n",
    "            with open(filename, encoding='utf-8') as f:\n",
    "                for l in f:\n",
    "                    text, label = l.strip().split('\\t')\n",
    "                    for t in text_segmentate(text, maxlen - 2, seps, strips):\n",
    "                        D.append((t, int(label)))\n",
    "        return D\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "    for text, label in batch:\n",
    "        token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "        batch_token_ids.append(token_ids)\n",
    "        batch_segment_ids.append(segment_ids)\n",
    "        batch_labels.append([label])\n",
    "\n",
    "    batch_token_ids = torch.tensor(sequence_padding(batch_token_ids), dtype=torch.long, device=device)\n",
    "    batch_segment_ids = torch.tensor(sequence_padding(batch_segment_ids), dtype=torch.long, device=device)\n",
    "    batch_labels = torch.tensor(batch_labels, dtype=torch.long, device=device)\n",
    "    return [batch_token_ids, batch_segment_ids], batch_labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f3761-830e-4ddd-9d77-5e5eb26b0304",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 双阶段训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd945a6-ab71-49da-87b2-f8d029a3b82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义bert上的模型结构\n",
    "class Model(BaseModel):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = build_transformer_model(config_path=config_path, \n",
    "                                            checkpoint_path=checkpoint_path, \n",
    "                                            with_pool=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense = nn.Linear(self.bert.configs['hidden_size'], 6)\n",
    "        \n",
    "    def forward(self, token_ids, segment_ids):\n",
    "        _, pooled_output = self.bert([token_ids, segment_ids])\n",
    "        output = self.dropout(pooled_output)\n",
    "        output = self.dense(output)\n",
    "        return output\n",
    "model = Model().to(device)\n",
    "\n",
    "# 定义使用的loss和optimizer，这里支持自定义\n",
    "model.compile(\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(model.parameters(), lr=2e-5),\n",
    ")\n",
    "\n",
    "class Evaluator(Callback):\n",
    "    \"\"\"评估与保存\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, global_step, epoch, logs=None):\n",
    "        val_acc = self.evaluate(valid_dataloader)\n",
    "        if val_acc >= self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('./best_model_1.pt')\n",
    "        print(f'val_acc: {val_acc:.5f}, best_val_acc: {self.best_val_acc:.5f}\\n')\n",
    "\n",
    "    # 定义评价函数\n",
    "    def evaluate(self, data):\n",
    "        total, right = 0., 0.\n",
    "        for x_true, y_true in data:\n",
    "            y_pred = model.predict(x_true).argmax(axis=1)\n",
    "            total += len(y_true)\n",
    "            right += (y_true == y_pred).sum().item()\n",
    "        acc = right / total\n",
    "        return acc\n",
    "\n",
    "def inference(texts):\n",
    "    '''单条样本推理\n",
    "    '''\n",
    "    ans = []\n",
    "    for text in texts:\n",
    "        token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "        token_ids = torch.tensor(token_ids, dtype=torch.long, device=device)[None, :]\n",
    "        segment_ids = torch.tensor(segment_ids, dtype=torch.long, device=device)[None, :]\n",
    "\n",
    "        logit = model.predict([token_ids, segment_ids])\n",
    "        y_pred = torch.argmax(torch.softmax(logit, dim=-1)).cpu().numpy()\n",
    "        ans.append(y_pred)\n",
    "    return ans\n",
    "\n",
    "def predict(file_path,output_path):\n",
    "    f = open(file_path, 'r', encoding='utf-8')\n",
    "    test_datas = f.readlines()\n",
    "    test_datas = [data.split('\\t')[0] for data in test_datas]\n",
    "    results = inference(test_datas)\n",
    "    f.close()\n",
    "\n",
    "    fw = open(output_path, 'w', encoding='utf-8')\n",
    "    for i in range(len(test_datas)):\n",
    "        fw.write(f\"{test_datas[i]}\\t{results[i]}\\n\")\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613085f-a7c2-4e22-8eb6-6f486c1f1ab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 第一阶段的训练\n",
    "- 做7折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee9f2eb-8fe3-4531-8b4d-e7625d0f10fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = [1, 42, 100, 142, 500, 1200, 2023]\n",
    "for i in range(7):\n",
    "    src_path = \"../data/train1.txt\"\n",
    "    df1 = pd.read_table(src_path, sep=\"\\t\", header=None)\n",
    "    shuffled_df1 = df1.sample(frac=1, random_state=state[i])\n",
    "    shuffled_df1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_df = shuffled_df1[:6500]\n",
    "    dev_df = shuffled_df1[6500:]\n",
    "    dev_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_df.to_csv(\"../data/one_times_data/train/\" + str(i) + \".txt\", sep=\"\\t\",\n",
    "                    index=False, header = None)\n",
    "    dev_df.to_csv(\"../data/one_times_data/dev/\" + str(i) + \".txt\", sep=\"\\t\",\n",
    "                    index=False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dbf14a-88cf-42c0-a468-19a4df850b47",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 08:41:37 - Start Training\n",
      "\n",
      "2023-10-09 08:41:37 - Epoch: 1/10\n",
      "407/407 [==============================] - 56s 138ms/step - loss: 0.7285 \n",
      "val_acc: 0.85600, best_val_acc: 0.85600\n",
      "\n",
      "\n",
      "2023-10-09 08:42:44 - Epoch: 2/10\n",
      "407/407 [==============================] - 53s 131ms/step - loss: 0.4126 \n",
      "val_acc: 0.86600, best_val_acc: 0.86600\n",
      "\n",
      "\n",
      "2023-10-09 08:43:49 - Epoch: 3/10\n",
      "407/407 [==============================] - 53s 130ms/step - loss: 0.3130 \n",
      "val_acc: 0.86600, best_val_acc: 0.86600\n",
      "\n",
      "\n",
      "2023-10-09 08:44:52 - Epoch: 4/10\n",
      " 19/407 [>.............................] - ETA: 52s - loss: 0.1906 "
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    train_dataloader = DataLoader(MyDataset(['../data/one_times_data/train/' + str(i) + \".txt\"]), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_dataloader = DataLoader(MyDataset(['../data/one_times_data/dev/' + str(i) + \".txt\"]), batch_size=batch_size, collate_fn=collate_fn)\n",
    "    evaluator = Evaluator()\n",
    "    model.fit(train_dataloader, epochs=10, steps_per_epoch=None, callbacks=[evaluator])\n",
    "    predict('../data/pred.txt', '../output/one_times/' + str(i) + \".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6029aa9-ba03-4308-9595-bfecb8261545",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 第二阶段的训练样本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13aff6-6904-47e0-a9ff-66edc31c8fe9",
   "metadata": {},
   "source": [
    "### 根据第一阶段的预测结果 单独提取预测为0的组成新的预测集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d125d18f-70c2-4f06-9d03-86ce728bc218",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 2, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m net_data_index \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     data_index \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m     net_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 2, saw 2\n"
     ]
    }
   ],
   "source": [
    "sub_path = \"../one_times/\"\n",
    "net_data_index = []\n",
    "for i in range(7):\n",
    "    df = pd.read_csv(sub_path + str(i) + \".txt\", sep=\"\\t\", header= None, )\n",
    "    data_index = []\n",
    "    net_data = []\n",
    "    for j in range(len(df)):\n",
    "        net_data.append(df[0][j])\n",
    "        data_index.append(df[1][j])\n",
    "    net_data_index.append(data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83019081-181f-4546-af4c-4c6e38e07788",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终投票结果： [0, 3, 3, 2, 3, 0, 3, 1, 3, 3, 1, 2, 0, 0, 2, 2, 2, 0, 1, 2, 0, 3, 3, 3, 3, 2, 3, 1, 3, 0, 1, 3, 0, 2, 3, 0, 3, 3, 1, 1, 0, 3, 0, 0, 2, 1, 2, 3, 0, 2, 2, 0, 3, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 2, 2, 3, 1, 3, 2, 1, 0, 2, 1, 0, 3, 2, 0, 2, 1, 1, 0, 1, 2, 0, 1, 0, 1, 0, 0, 3, 1, 0, 2, 2, 2, 2, 0, 3, 3, 0, 0, 1, 1, 3, 1, 1, 1, 0, 1, 1, 0, 2, 0, 0, 1, 1, 3, 2, 0, 1, 3, 2, 0, 0, 1, 3, 3, 3, 2, 3, 1, 1, 2, 3, 0, 0, 1, 1, 2, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 0, 0, 3, 2, 2, 3, 0, 0, 2, 3, 3, 1, 0, 0, 0, 2, 2, 3, 2, 3, 1, 1, 0, 1, 3, 3, 1, 0, 3, 1, 2, 3, 0, 1, 0, 0, 0, 2, 0, 3, 3, 3, 0, 3, 3, 2, 0, 2, 1, 1, 0, 3, 1, 0, 0, 3, 3, 3, 0, 1, 3, 2, 1, 1, 2, 3, 1, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 1, 3, 0, 1, 1, 1, 1, 2, 3, 2, 1, 3, 0, 2, 3, 3, 3, 0, 1, 1, 0, 3, 1, 3, 3, 0, 0, 1, 3, 3, 0, 1, 2, 0, 3, 0, 1, 0, 2, 2, 1, 0, 3, 0, 3, 2, 3, 1, 1, 2, 0, 1, 1, 3, 0, 0, 2, 3, 2, 2, 0, 2, 3, 3, 0, 2, 0, 1, 0, 3, 1, 1, 0, 1, 0, 2, 1, 3, 2, 2, 1, 2, 0, 3, 1, 1, 1, 2, 3, 2, 0, 0, 3, 0, 0, 1, 2, 2, 3, 3, 3, 1, 1, 0, 0, 0, 3, 1, 3, 0, 3, 3, 3, 2, 2, 0, 3, 0, 0, 3, 3, 3, 0, 0, 3, 0, 2, 3, 3, 2, 2, 2, 3, 3, 2, 1, 3, 0, 0, 0, 3, 3, 1, 3, 2, 3, 2, 3, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 1, 0, 3, 3, 2, 1, 1, 1, 0, 1, 0, 3, 2, 3, 3, 2, 3, 3, 2, 0, 0, 0, 2, 3, 2, 3, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 2, 3, 0, 1, 2, 1, 3, 1, 1, 1, 1, 1, 3, 1, 0, 2, 1, 1, 0, 0, 1, 0, 1, 1, 3, 1, 2, 0, 2, 3, 0, 0, 1, 0, 0, 3, 2, 0, 1, 2, 0, 1, 3, 1, 0, 3, 2, 1, 3, 3, 1, 0, 2, 2, 0, 0, 1, 0, 2, 1, 0, 0, 2, 0, 0, 3, 3, 1, 2, 0, 1, 0, 2, 1, 2, 2, 2, 0, 2, 3, 2, 2, 1, 2, 1, 3, 0, 1, 1, 2, 1, 0, 3, 2, 0, 3, 1, 3, 3, 3, 0, 0, 2, 1, 1, 1, 1, 2, 2, 3, 3, 2, 1, 2, 3, 3, 1, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 0, 3, 0, 2, 1, 0, 0, 3, 0, 2, 0, 2, 1, 0, 3, 3, 2, 0, 2, 3, 1, 0, 0, 2, 3, 1, 1, 2, 2, 3, 1, 1, 0, 3, 2, 2, 1, 0, 3, 1, 1, 2, 3, 3, 2, 0, 3, 3, 2, 0, 1, 3, 2, 3, 0, 1, 2, 0, 3, 2, 3, 1, 2, 0, 1, 1, 0, 1, 3, 0, 1, 2, 3, 2, 1, 3, 1, 0, 2, 0, 0, 1, 0, 3, 0, 2, 3, 3, 0, 2, 3, 3, 1, 3, 1, 1, 3, 0, 2, 3, 0, 3, 2, 3, 0, 2, 1, 1, 2, 1, 1, 1, 0, 3, 3, 0, 2, 3, 3, 2, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 1, 2, 3, 3, 3, 0, 1, 1, 0, 2, 3, 3, 2, 3, 2, 1, 1, 3, 3, 2, 1, 0, 0, 1, 3, 2, 3, 2, 2, 2, 3, 1, 3, 2, 3, 3, 0, 2, 3, 1, 2, 2, 3, 1, 0, 0, 1, 0, 3, 0, 1, 0, 2, 1, 2, 3, 3, 1, 1, 2, 3, 2, 0, 3, 1, 3, 2, 1, 0, 3, 1, 2, 0, 0, 2, 3, 0, 3, 0, 0, 1, 1, 3, 0, 2, 2, 2, 1, 3, 1, 0, 3, 0, 0, 2, 0, 1, 0, 0, 2, 3, 3, 1, 3, 1, 3, 1, 0, 3, 3, 0, 0, 1, 3, 1, 1, 2, 3, 1, 0, 2, 1, 2, 1, 3, 3, 1, 3, 0, 0, 2, 1, 2, 3, 2, 0, 2, 2, 0, 3, 0, 0, 2, 0, 2, 0, 1, 1, 0, 2, 0, 0, 0, 2, 3, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 0, 2, 3, 3, 1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 0, 1, 3, 3, 3, 1, 0, 3, 1, 2, 3, 2, 2, 1, 2, 2, 2, 1, 3, 1, 3, 3, 1, 2, 3, 3, 2, 1, 3, 2, 1, 3, 0, 0, 0, 1, 3, 1, 1, 0, 1, 2, 0, 1, 0, 0, 0, 3, 2, 0, 1, 0, 1, 1, 2, 1, 2, 1, 1, 3, 3, 2, 0, 3, 3, 3, 2, 2, 2, 0, 3, 1, 0, 1, 0, 3, 2, 1, 3, 3, 0, 1, 1, 3, 0, 2, 0, 3, 1, 3, 1, 0, 1, 0, 0, 2, 1, 0, 3, 3, 0, 0, 0, 0, 1, 1, 2, 0, 0, 2, 2, 2, 3, 1, 0, 1, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# 对每个位置的数字进行投票\n",
    "votes = []\n",
    "for i in range(len(data_index)):\n",
    "    current_votes = [lst[i] for lst in net_data_index]\n",
    "    counter = Counter(current_votes)\n",
    "    winning_number = counter.most_common(1)[0][0]  # 默认是如果全部不相同取第一个\n",
    "    votes.append(winning_number)\n",
    "# 输出最终的投票结果\n",
    "print(\"最终投票结果：\", votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37d06ded-2eb4-45ef-98b2-8269987b9bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_time = [net_data, votes]\n",
    "pd.DataFrame(one_time).T.to_csv(\"submit1.txt\" , sep=\"\\t\", index=False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b4b4c5d-e70d-4e8a-8c9a-de656bf4c75f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0    277\n",
      "1    260\n",
      "3    251\n",
      "2    212\n",
      "Name: count, dtype: int64\n",
      "1\n",
      "0    277\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table(\"submit1.txt\", sep=\"\\t\", header= None)\n",
    "print(pd.DataFrame(df[1]).value_counts())\n",
    "data = []\n",
    "for i in range(len(df)):\n",
    "    if df[1][i] == 0:\n",
    "        data.append(df.iloc[i])\n",
    "print(pd.DataFrame(data)[1].value_counts())\n",
    "pd.DataFrame(data).to_csv(\"../data/pred2.txt\", sep=\"\\t\", index=False, header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb55ec-30c3-4cf8-947e-11f20857e75e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 第二阶段训练\n",
    "- 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bba0cd-66ae-4b93-9d42-943caf942436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(Callback):\n",
    "    \"\"\"评估与保存\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, global_step, epoch, logs=None):\n",
    "        val_acc = self.evaluate(valid_dataloader)\n",
    "        if val_acc >= self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('./best_model_2.pt')\n",
    "        print(f'val_acc: {val_acc:.5f}, best_val_acc: {self.best_val_acc:.5f}\\n')\n",
    "\n",
    "    # 定义评价函数\n",
    "    def evaluate(self, data):\n",
    "        total, right = 0., 0.\n",
    "        for x_true, y_true in data:\n",
    "            y_pred = model.predict(x_true).argmax(axis=1)\n",
    "            total += len(y_true)\n",
    "            right += (y_true == y_pred).sum().item()\n",
    "        acc = right / total\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f55d2aa-e587-4bbf-9487-213d61880333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = [1, 42, 100, 142, 500, 1200, 2023]\n",
    "for i in range(7):\n",
    "    src_path = \"../data/train2.txt\"\n",
    "    df1 = pd.read_table(src_path, sep=\"\\t\", header=None)\n",
    "    shuffled_df1 = df1.sample(frac=1, random_state=state[i])\n",
    "    shuffled_df1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_df = shuffled_df1[:1700]\n",
    "    dev_df = shuffled_df1[1700:]\n",
    "    dev_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_df.to_csv(\"../data/two_times_data/train/\" + str(i) + \".txt\", sep=\"\\t\",\n",
    "                    index=False, header = None)\n",
    "    dev_df.to_csv(\"../data/two_times_data/dev/\" + str(i) + \".txt\", sep=\"\\t\",\n",
    "                    index=False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcaaff2-43c8-4b19-a4f1-358afefb467b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 08:38:06 - Start Training\n",
      "\n",
      "2023-10-09 08:38:06 - Epoch: 1/10\n",
      "213/213 [==============================] - 27s 125ms/step - loss: 1.1183 \n",
      "val_acc: 0.85135, best_val_acc: 0.85135\n",
      "\n",
      "\n",
      "2023-10-09 08:38:43 - Epoch: 2/10\n",
      "213/213 [==============================] - 27s 128ms/step - loss: 0.3578 \n",
      "val_acc: 0.94595, best_val_acc: 0.94595\n",
      "\n",
      "\n",
      "2023-10-09 08:39:21 - Epoch: 3/10\n",
      "213/213 [==============================] - 27s 125ms/step - loss: 0.1924 \n",
      "val_acc: 0.93919, best_val_acc: 0.94595\n",
      "\n",
      "\n",
      "2023-10-09 08:39:49 - Epoch: 4/10\n",
      "213/213 [==============================] - 27s 128ms/step - loss: 0.1056 \n",
      "val_acc: 0.92568, best_val_acc: 0.94595\n",
      "\n",
      "\n",
      "2023-10-09 08:40:16 - Epoch: 5/10\n",
      "213/213 [==============================] - 27s 126ms/step - loss: 0.0755 \n",
      "val_acc: 0.92568, best_val_acc: 0.94595\n",
      "\n",
      "\n",
      "2023-10-09 08:40:44 - Epoch: 6/10\n",
      " 31/213 [===>..........................] - ETA: 23s - loss: 0.0072 "
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "for i in range(7):\n",
    "    train_dataloader = DataLoader(MyDataset(['../data/two_times_data/train/' + str(i) + \".txt\"]), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_dataloader = DataLoader(MyDataset(['../data/two_times_data/dev/' + str(i) + \".txt\"]), batch_size=batch_size, collate_fn=collate_fn)\n",
    "    evaluator = Evaluator()\n",
    "    model.fit(train_dataloader, epochs=10, steps_per_epoch=None, callbacks=[evaluator])\n",
    "    predict('../data/pred2.txt', '../output/two_times/' + str(i) + \".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68174213-8411-4cfa-afac-b4a61be609e9",
   "metadata": {},
   "source": [
    "### 根据预测结果投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080608bc-eb29-430f-b5b2-069e6913b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = \"../output/two_times/\"\n",
    "net_data_index = []\n",
    "for i in range(7):\n",
    "    df = pd.read_csv(sub_path + str(i) + \".txt\", sep=\"\\t\", header= None)\n",
    "    data_index = []\n",
    "    net_data = []\n",
    "    for j in range(len(df)):\n",
    "        net_data.append(df[0][j])\n",
    "        data_index.append(df[1][j])\n",
    "    net_data_index.append(data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544e1d4-c15d-41a6-8b4a-c0c8d0c43110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每个位置的数字进行投票\n",
    "votes = []\n",
    "for i in range(len(data_index)):\n",
    "    current_votes = [lst[i] for lst in net_data_index]\n",
    "    counter = Counter(current_votes)\n",
    "    winning_number = counter.most_common(1)[0][0]\n",
    "    votes.append(winning_number)\n",
    "# 输出最终的投票结果\n",
    "print(\"最终投票结果：\", votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afecbc63-088d-4101-8730-fbae1f9d0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_time = [net_data, votes]\n",
    "pd.DataFrame(two_time).T.to_csv(\"submit2.txt\" , sep=\"\\t\", index=False, header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f665b-f5e9-4561-81a2-e69ff2cda01a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 拼接结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6b83921-7745-4dfb-9da1-bc5decccdfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1    277\n",
      "3    276\n",
      "0    266\n",
      "2    181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_table(\"submit1.txt\", sep=\"\\t\", header= None)\n",
    "print(pd.DataFrame(df1[1]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e75092b-5d38-4088-8e7e-33d167f8ffc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_table(\"submit2.txt\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "586810db-456d-4248-92fa-5acfb655c62f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "11 1\n",
      "12 2\n",
      "13 3\n",
      "14 4\n",
      "16 5\n",
      "29 6\n",
      "32 7\n",
      "35 8\n",
      "42 9\n",
      "43 10\n",
      "48 11\n",
      "51 12\n",
      "53 13\n",
      "54 14\n",
      "59 15\n",
      "60 16\n",
      "61 17\n",
      "62 18\n",
      "64 19\n",
      "67 20\n",
      "73 21\n",
      "75 22\n",
      "78 23\n",
      "82 24\n",
      "90 25\n",
      "92 26\n",
      "93 27\n",
      "96 28\n",
      "97 29\n",
      "101 30\n",
      "104 31\n",
      "105 32\n",
      "112 33\n",
      "115 34\n",
      "118 35\n",
      "123 36\n",
      "128 37\n",
      "139 38\n",
      "140 39\n",
      "143 40\n",
      "144 41\n",
      "145 42\n",
      "148 43\n",
      "150 44\n",
      "151 45\n",
      "153 46\n",
      "154 47\n",
      "155 48\n",
      "161 49\n",
      "166 50\n",
      "168 51\n",
      "170 52\n",
      "175 53\n",
      "176 54\n",
      "186 55\n",
      "188 56\n",
      "189 57\n",
      "190 58\n",
      "196 59\n",
      "200 60\n",
      "204 61\n",
      "207 62\n",
      "208 63\n",
      "212 64\n",
      "222 65\n",
      "224 66\n",
      "226 67\n",
      "227 68\n",
      "228 69\n",
      "230 70\n",
      "243 71\n",
      "251 72\n",
      "256 73\n",
      "257 74\n",
      "261 75\n",
      "264 76\n",
      "266 77\n",
      "268 78\n",
      "272 79\n",
      "274 80\n",
      "281 81\n",
      "285 82\n",
      "286 83\n",
      "287 84\n",
      "291 85\n",
      "295 86\n",
      "297 87\n",
      "299 88\n",
      "303 89\n",
      "305 90\n",
      "306 91\n",
      "313 92\n",
      "318 93\n",
      "321 94\n",
      "322 95\n",
      "324 96\n",
      "334 97\n",
      "335 98\n",
      "336 99\n",
      "340 100\n",
      "346 101\n",
      "348 102\n",
      "349 103\n",
      "353 104\n",
      "354 105\n",
      "356 106\n",
      "369 107\n",
      "382 108\n",
      "383 109\n",
      "384 110\n",
      "385 111\n",
      "386 112\n",
      "387 113\n",
      "393 114\n",
      "400 115\n",
      "402 116\n",
      "411 117\n",
      "412 118\n",
      "413 119\n",
      "414 120\n",
      "418 121\n",
      "426 122\n",
      "428 123\n",
      "434 124\n",
      "446 125\n",
      "450 126\n",
      "451 127\n",
      "453 128\n",
      "459 129\n",
      "460 130\n",
      "462 131\n",
      "463 132\n",
      "465 133\n",
      "466 134\n",
      "469 135\n",
      "472 136\n",
      "476 137\n",
      "483 138\n",
      "486 139\n",
      "487 140\n",
      "489 141\n",
      "492 142\n",
      "495 143\n",
      "496 144\n",
      "503 145\n",
      "509 146\n",
      "523 147\n",
      "526 148\n",
      "532 149\n",
      "539 150\n",
      "549 151\n",
      "560 152\n",
      "562 153\n",
      "568 154\n",
      "569 155\n",
      "570 156\n",
      "571 157\n",
      "573 158\n",
      "577 159\n",
      "581 160\n",
      "592 161\n",
      "597 162\n",
      "605 163\n",
      "609 164\n",
      "614 165\n",
      "617 166\n",
      "623 167\n",
      "626 168\n",
      "636 169\n",
      "637 170\n",
      "638 171\n",
      "639 172\n",
      "640 173\n",
      "642 174\n",
      "648 175\n",
      "649 176\n",
      "657 177\n",
      "658 178\n",
      "660 179\n",
      "664 180\n",
      "672 181\n",
      "675 182\n",
      "690 183\n",
      "699 184\n",
      "702 185\n",
      "716 186\n",
      "727 187\n",
      "734 188\n",
      "738 189\n",
      "739 190\n",
      "741 191\n",
      "745 192\n",
      "746 193\n",
      "756 194\n",
      "760 195\n",
      "767 196\n",
      "770 197\n",
      "772 198\n",
      "773 199\n",
      "777 200\n",
      "779 201\n",
      "780 202\n",
      "784 203\n",
      "786 204\n",
      "787 205\n",
      "789 206\n",
      "791 207\n",
      "792 208\n",
      "793 209\n",
      "801 210\n",
      "804 211\n",
      "813 212\n",
      "814 213\n",
      "822 214\n",
      "823 215\n",
      "829 216\n",
      "832 217\n",
      "834 218\n",
      "835 219\n",
      "837 220\n",
      "838 221\n",
      "839 222\n",
      "842 223\n",
      "844 224\n",
      "845 225\n",
      "846 226\n",
      "852 227\n",
      "858 228\n",
      "859 229\n",
      "866 230\n",
      "867 231\n",
      "868 232\n",
      "871 233\n",
      "872 234\n",
      "876 235\n",
      "878 236\n",
      "879 237\n",
      "887 238\n",
      "914 239\n",
      "915 240\n",
      "920 241\n",
      "925 242\n",
      "926 243\n",
      "927 244\n",
      "932 245\n",
      "943 246\n",
      "950 247\n",
      "953 248\n",
      "955 249\n",
      "961 250\n",
      "965 251\n",
      "967 252\n",
      "969 253\n",
      "972 254\n",
      "974 255\n",
      "975 256\n",
      "976 257\n",
      "981 258\n",
      "982 259\n",
      "984 260\n",
      "988 261\n",
      "989 262\n",
      "991 263\n",
      "995 264\n",
      "997 265\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for i in range(len(df1)):\n",
    "    if df1[1][i] == 0:\n",
    "        print(i, num)\n",
    "        df1[1][i] = df2[1][num]\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38bb7deb-3689-481c-a504-f75ac7a3d946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv(\"../output/submit.txt\", sep=\"\\t\", index=False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06775a5d-f420-407b-a25c-bdeebcbaf88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7785c-b5f6-4018-97b5-93c00782999b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4340a78-82cc-48d7-8842-075aef160526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_table(\"../output/submit.txt\", sep=\"\\t\", header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4953ba62-879f-4c04-9ff8-42834d741a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "1    275\n",
       "3    267\n",
       "2    210\n",
       "4     98\n",
       "0     87\n",
       "5     63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df1[1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a6a71-c346-445c-a888-0dc90251fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
